---
title: "Predicting Stroke and Myocardial Infarction Risk in Takayasu Arteritis with Automated Machine Learning-based Models"
---


```{r}
library(MASS)
library(leaps)
library(glmnet)
library(magrittr)
library(readxl)
library(pROC)
library(caret)
library(dplyr)
```
```{r}
source("~/My_functions/my_functions.R")
```
```{r sample size for criterion B3}
parameters<-25
Outcome_proportion<-0.15
Arbitrary_sample_size <-100
E<-Outcome_proportion*Arbitrary_sample_size
n<-Arbitrary_sample_size
InLnull<-E*log(E/n)+(n-E)*log(1-E/n)
max_Rsq<-1-exp(2*InLnull/n)
max_Rsq

explain<-0.15 #If we assume, conservatively, that the new model will explain 15% of the variability

anticipated_Rsq<-round(explain*max_Rsq,2)

anticipated_Rsq

message <- paste("在Stata中输入: pmsampsize, type(b) rsquared(", anticipated_Rsq, ") parameters(", parameters, ") prevalence(", Outcome_proportion, ")", sep = "")

cat(message)

```

sample size for criterion B2
```{r sample size for criterion B2}
Sample_size<-exp((-0.508+0.259*log(Outcome_proportion)+0.504*log(parameters)-log(0.05))/0.544)
Sample_size
EPP<-Sample_size*Outcome_proportion/10
EPP
```

```{r }
data <- read_excel("~/Data.xlsx")
dim(data) 
continuous_cols <- 4:43
data[, continuous_cols] <- apply(data[, continuous_cols], 2, as.numeric, na.strings = "")
factor_cols <- setdiff(names(data), names(data[, continuous_cols]))
data[, factor_cols] <- lapply(data[, factor_cols], as.factor)
```

```{r}
variables_with_missing <- names(data)[colSums(is.na(data)) > 0]
length(variables_with_missing)
missing_proportions <- colSums(is.na(data[, variables_with_missing])) / nrow(data) * 100
missing_data_summary <- data.frame(Variable = variables_with_missing, Missing_Proportion = missing_proportions)
library(ggplot2)
ggplot(missing_data_summary, aes(x = reorder(Variable, Missing_Proportion), y = Missing_Proportion)) +
  geom_bar(stat = "identity", fill = "skyblue", width = 0.5) +
  labs(x = "Variable", y = "Missing Proportion (%)") +
  ggtitle("Missing Data Summary") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

variables_to_remove <- names(missing_proportions[missing_proportions > 5])
length(variables_to_remove)

data <- data[, !(names(data) %in% variables_to_remove)]
dim(data) #703 158

variables_with_missing <- names(data)[colSums(is.na(data)) > 0]
length(variables_with_missing)

library(mice)
imputed_data <- mice(data[, variables_with_missing], method = "pmm", m = 5, maxit = 50)
event_logs <- imputed_data$log
summary(event_logs)
str(event_logs)

imputed_data_complete <- complete(imputed_data)
sapply(imputed_data_complete, class)
variables_with_remaining_missing <- names(imputed_data_complete)[colSums(is.na(imputed_data_complete)) > 0]
variables_to_replace <- names(imputed_data_complete)
data[, variables_to_replace] <- imputed_data_complete[, variables_to_replace]
variables_with_missing <- names(data)[colSums(is.na(data)) > 0]
variables_with_missing

```{r}
variable_info <- data.frame(Variable = character(), Type = character(), Levels = character(), stringsAsFactors = FALSE)
for (variable in names(data)) {
  variable_type <- class(data[[variable]])
  if (is.factor(data[[variable]])) {
    factor_levels <- levels(data[[variable]])
    num_levels <- length(factor_levels)
  } else {
    factor_levels <- ""
    num_levels <- ""
  }
  variable_info <- rbind(variable_info, data.frame(Variable = variable, Type = variable_type, Levels = paste(factor_levels, collapse = ","), Num_Levels = num_levels, stringsAsFactors = FALSE))
}
print(variable_info)
```

```{r}
removed_variables <- variable_info$Variable[variable_info$Num_Levels == 1]
data <- data[, !names(data) %in% removed_variables]
print(removed_variables)
dim(data)
```
```{r}
library(caret)
nzv <- nearZeroVar(data, saveMetrics= TRUE)
nzv[nzv$nzv,]
nzv <- nearZeroVar(data)
filteredDescr <- data[, -nzv]
dim(filteredDescr)
```
```{r }
data<-filteredDescr
dim(data)
save(data,file="~/data.rdata")

```

```{r }
load("~/Data/available_models.rdata")
load("~/Data/available_seeds.rdata")
load("~/Data/brier_table.rdata")
load("~/Data/BSR_variable_combinations.rdata")
load("~/Data/candidate_variables.rdata")
load("~/Data/classification_table.rdata")
load("~/Data/data.rdata")
load("~/Data/fit_models.rdata")
load("~/Data/LASSO_variable_combinations.rdata")
load("~/Data/LASSO_variable_combinations.rdata")
load("~/Data/results_df.rdata")
load("~/Data/significant_variables.rdata")

```

```{r}
discover_queue <- data[data$Group == "Discover", ]
validation_queue <- data[data$Group == "Validation", ]
```

```{r }
significant_variables <- c()
for (col in names(discover_queue)[-exclude_cols]) {
  if (is.factor(discover_queue[[col]]) && length(unique(discover_queue[[col]])) >= 2) {
    formula <- as.formula(paste("Outcome ~", col))
    model <- glm(formula, data = discover_queue, family = binomial)
    p_value <- summary(model)$coefficients[2, 4]
    if (p_value < 0.05) {
      significant_variables <- c(significant_variables, col)
    }
  }
}
significant_variables
```

```{r }
regression_results <- list()
for (variable in significant_variables) {
  formula <- as.formula(paste("Outcome ~", variable))
  model <- glm(formula, data = discover_queue, family = binomial)
  coef_summary <- confint(model)[2, ]  
  beta_value <- coef(model)[2]
  lower_ci <- coef_summary[1]
  upper_ci <- coef_summary[2]
  regression_results[[variable]] <- list(beta_value = beta_value, lower_ci = lower_ci, upper_ci = upper_ci)
}

result_df <- data.frame(Variable = names(regression_results),
                        Beta_Values = sapply(regression_results, function(x) x$beta_value),
                        Lower_CI = sapply(regression_results, function(x) x$lower_ci),
                        Upper_CI = sapply(regression_results, function(x) x$upper_ci),
                        stringsAsFactors = FALSE)

result_df <- result_df[order(result_df$Beta_Values), ]

result_df$Variable <- factor(result_df$Variable, levels = result_df$Variable)

library(ggplot2)
library(extrafont)


ggplot(result_df, aes(x = Beta_Values, y = Variable)) +
  geom_segment(aes(x = Lower_CI, xend = Upper_CI, y = Variable, yend = Variable),
               color = "black", size = 0.5) +
  geom_errorbarh(aes(xmin = Lower_CI, xmax = Upper_CI, y = Variable),
                 height = 0.2, color = "black", size = 0.5, show.legend = FALSE) +
  geom_segment(aes(x = -4, xend = 4, y = 0, yend = 0),
               color = "black", linetype = "solid", size = 0.5) +
  geom_vline(xintercept = 0, linetype = "solid", size = 0.3) +
  geom_point(aes(shape = factor(sign(Beta_Values)), fill = factor(sign(Beta_Values))),
             size = 5, color = "black") +
  geom_text(aes(label = paste(sprintf("%.3f", Beta_Values), "[", sprintf("%.3f", Lower_CI), ",", sprintf("%.3f", Upper_CI), "]")),
            x = 4, hjust = 0, size = 3, vjust = 0.5, nudge_x = 0.1, family = "Times New Roman", fontface = "bold", color = "black") +
  labs(x = "Beta Value", y = "Variable") +
  scale_shape_manual(values = c(22, 21), labels = c("Negative", "Positive")) +
  scale_fill_manual(values = c("red", "red"), labels = c("Negative", "Positive")) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.margin = margin(0, 1, 0, 0, "cm"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line.y = element_blank(),
        text = element_text(family = "Times New Roman", face = "bold", color = "black")) +
  coord_cartesian(xlim = c(-4, 8)) +
  scale_x_continuous(breaks = seq(-4, 4, 2), limits = c(-4, 4))
```

```{r }
library(dplyr)
subset_data <- data[, significant_variables]
subset_data <- sapply(subset_data, as.numeric)
cor_matrix <- cor(subset_data)
library(ggplot2)
library(reshape2)
cor_matrix_melted <- melt(cor_matrix)

cor_matrix_melted <- cor_matrix_melted %>%
  filter(row_number() < match(Var1, Var2)) %>%
  mutate(xmin = as.integer(as.factor(Var1)) - 0.5,
         xmax = as.integer(as.factor(Var1)) + 0.5,
         ymin = as.integer(as.factor(Var2)) - 0.5,
         ymax = as.integer(as.factor(Var2)) + 0.5)

ggplot(cor_matrix_melted, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, limit = c(-1, 1), name = "Correlation") +
  geom_text(aes(label = ifelse(abs(value) > 0.3 & value <= 1, round(value, 2), "")),
            color = "black",
            size = 3,
            family = "Times New Roman") +
  geom_rect(aes(xmin = xmin - 1, xmax = xmax - 1, ymin = ymin, ymax = ymax), color = "gray", fill = NA, size = 0.2) +  # 添加灰色边框，向左移一个单元格距离
  labs(x = "Variable 1", y = "Variable 2", title = "Correlation Matrix") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid = element_blank()) +
  coord_fixed() +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0))

```

```{r }
subset<- data[, c("Outcome", significant_variables)]
leaps <- regsubsets(Outcome ~ ., data = subset)
summary_leaps <- summary(leaps)
which.min(summary_leaps$cp)
which.max(summary_leaps$adjr2) 
which.min(summary_leaps$bic) 

plot(leaps,scale="adjr2")
best_vars <- summary_leaps$which[which.min(summary_leaps$cp), ]
best_vars <- best_vars[-1] 

variable_names <- names(subset)[-1][best_vars]

BSR_variable_combinations<-variable_names

BSR_variable_combinations

```

LASSO_subset<- data[, c("Outcome", significant_variables)]
LASSO_subset[, -1] <- apply(LASSO_subset[, -1], 2, as.numeric)
library(glmnet)
str(LASSO_subset)
LASSO_matrix <- as.matrix(LASSO_subset[, -1])  # 排除第一列 Outcome
outcome <- LASSO_subset$Outcome
lasso_model <- glmnet(LASSO_matrix, outcome, family = "binomial", alpha = 1)
plot(lasso_model, xvar = "lambda", label = TRUE)

cv_model <- cv.glmnet(LASSO_matrix, outcome, family = "binomial", alpha = 1)
plot(cv_model)

ridge.coef1 <- predict(lasso_model, s=cv_model$lambda.1se, type = "coefficients")
ridge.coef2 <- predict(lasso_model, s=cv_model$lambda.min, type = "coefficients")

LASSO_variable_combinations <- rownames(ridge.coef1)[ridge.coef1[, "s1"] != 0][-1]
LASSO_variable_combinations <- rownames(ridge.coef2)[ridge.coef2[, "s1"] != 0][-1]

LASSO_variable_combinations
save(LASSO_variable_combinations,file="~/建模/Data/LASSO_variable_combinations.rdata")
```

```{r }
# candidate_variables <- intersect(LASSO_variable_combinations, BSR_variable_combinations)
candidate_variables<-LASSO_variable_combinations
```

```{r}
library(caret)
all_models <- getModelInfo()
classification_models <- list()
for (model_name in names(all_models)) {
  model <- all_models[[model_name]]
  if ("Classification" %in% model$type) {
    classification_models[[model_name]] <- model
  }
}

classification_table <- data.frame(Name = character(),
                                   Type = character(),
                                   Library = character(),
                                   Parameters = character(),
                                   Tags = character(),
                                   stringsAsFactors = FALSE)

for (model_name in names(classification_models)) {
  model <- classification_models[[model_name]]
  model_data <- data.frame(
    Name = model_name,
    Type = model$type,
    Library = paste(model$library, collapse = ", "),
    Parameters = paste(model$parameters$parameter, collapse = ", "),
    Tags = paste(model$tags, collapse = ", "),
    stringsAsFactors = FALSE
  )
  classification_table <- rbind(classification_table, model_data)
}

dim(classification_table)
classification_table <- classification_table[classification_table$Type != "Regression", ]
dim(classification_table)

```

```{r }
dim(classification_table)
length(classification_table$Name)
save(classification_table,file="~/Data/classification_table.rdata")
```

```{r }
library(doParallel)
closeAllConnections()
cl <- makePSOCKcluster(32)
registerDoParallel(cl)
results <- list()
fit_models <- list()  
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)

# Rename the levels to valid variable names
levels(discover_queue$Outcome) <- c("No", "Yes")

for (i in 1:nrow(available_seeds)) {
  model_name <- available_seeds$模型名字[i]
  fit_name <- paste(model_name, "Fit", sep = "_")
  
  seed <- available_seeds$seed[i]  # 获取种子的值
  
  set.seed(seed) 
  tryCatch({
    assign(fit_name, train(Outcome ~ ., 
                           data = discover_queue[, c("Outcome", candidate_variables)], 
                           method = model_name, 
                           trControl = fitControl,
                           metric = "ROC"))
    
    pred_training <- predict(get(fit_name), newdata = discover_queue[, c("Outcome", candidate_variables)], type = "prob")
    roc_training <- roc(discover_queue$Outcome, pred_training[, "Yes"])
    auc_training <- auc(roc_training)
    auc_ci_training <- ci(auc_training)
    
    pred_validation <- predict(get(fit_name), newdata = validation_queue[, c("Outcome", candidate_variables)], type = "prob")
    roc_validation <- roc(validation_queue$Outcome, pred_validation[, "Yes"])
    auc_validation <- auc(roc_validation)
    auc_ci_validation <- ci(auc_validation)
    
    result <- c(model_name, fit_name, auc_training, auc_ci_training[1],  
                auc_ci_training[3], auc_validation, auc_ci_validation[1], auc_ci_validation[3], seed) 
    
    results[[i]] <- result
    fit_models[[fit_name]] <- get(fit_name) 
    
  }, error = function(e) {
    warning(paste("Error encountered for model", model_name, ". Skipping this model."))
  })
}


results_df <- do.call(rbind, results)

colnames(results_df) <- c("")  # user-defined
results_df<-data.frame(results_df)
best_model <- results_df[which.max(results_df$验证集AUC), "fit_name"]
reference_roc_training <- roc(discover_queue$Outcome, predict(get(best_model), newdata = discover_queue[, c("Outcome", candidate_variables)], type = "prob")[, "Yes"])
reference_roc_validation <- roc(validation_queue$Outcome, predict(get(best_model), newdata = validation_queue[, c("Outcome", candidate_variables)], type = "prob")[, "Yes"])

results_df$p_value_train <- sapply(results_df$fit_name, function(fit_name) {
  if (fit_name != best_model) {
    model_roc <- roc(discover_queue$Outcome, predict(get(fit_name), newdata = discover_queue[, c("Outcome", candidate_variables)], type = "prob")[, "Yes"])
    p_value <- roc.test(reference_roc_training, model_roc)$p.value
    return(p_value)
  } else {
    return(NA)  
  }
})

results_df$p_value_val <- sapply(results_df$fit_name, function(fit_name) {
  if (fit_name != best_model) {
    model_roc <- roc(validation_queue$Outcome, predict(get(fit_name), newdata = validation_queue[, c("Outcome", candidate_variables)], type = "prob")[, "Yes"])
    p_value <- roc.test(reference_roc_validation, model_roc)$p.value
    return(p_value)
  } else {
    return(NA)  
  }
})

colnames(results_df) <- c("") # # user-defined
save(results_df, file = "~/Data/results_df.rdata")
save(fit_models, file = "~/Data/fit_models.rdata")
stopCluster(cl)
```

```{r}
library(ggplot2)
results_df$ValidationAUC <- as.numeric(results_df$ValidationAUC)
results_df$ValidationAUC_lower <- as.numeric(results_df$ValidationAUC_lower)
results_df$ValidationAUC_upper <- as.numeric(results_df$ValidationAUC_upper)
results_df$TrainingAUC <- as.numeric(results_df$TrainingAUC)
results_df$TrainingAUC_lower <- as.numeric(results_df$TrainingAUC_lower)
results_df$TrainingAUC_upper <- as.numeric(results_df$TrainingAUC_upper)
results_df <- results_df[order(-results_df$ValidationAUC), ]
results_df$ModelName <- factor(results_df$ModelName, levels = results_df$ModelName)
results_df_top10 <- head(results_df, 20)
results_df_top10 <- results_df_top10[order(results_df_top10$ValidationAUC), ]
results_df_top10$ModelName <- factor(results_df_top10$ModelName, levels = results_df_top10$ModelName)

ggplot(results_df_top10, aes(x = ValidationAUC, y = ModelName)) +
  geom_segment(aes(x = ValidationAUC_lower, xend = ValidationAUC_upper, y = ModelName, yend = ModelName),
               color = "black", size = 0.5) +
  geom_errorbarh(aes(xmin = ValidationAUC_lower, xmax = ValidationAUC_upper, y = ModelName),
                 height = 0.2, color = "black", size = 0.5, show.legend = FALSE) +
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 0),
               color = "black", linetype = "solid", size = 0.5) +
  geom_vline(xintercept = 0.5, linetype = "solid", size = 0.3) +
  geom_point(aes(shape = factor(sign(ValidationAUC)), fill = factor(sign(ValidationAUC))),
             size = 5, color = "black") +
  geom_text(aes(label = paste(sprintf("%.3f", ValidationAUC), "[", sprintf("%.3f", ValidationAUC_lower), ",", sprintf("%.3f", ValidationAUC_upper), "]")),
            x = 1, hjust = 0, size = 3, vjust = 0.5, nudge_x = 0.1, family = "Times New Roman", fontface = "bold", color = "black") +
  labs(x = "Validation AUC", y = "Model Name") +
  scale_shape_manual(values = c(22, 21), labels = c("Negative", "Positive")) +
  scale_fill_manual(values = c("red", "red"), labels = c("Negative", "Positive")) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.margin = margin(0, 2, 0, 0, "cm"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line.y = element_blank(),
        text = element_text(family = "Times New Roman", face = "bold", color = "black")) +
  coord_cartesian(xlim = c(0, 2)) +
  scale_x_continuous(breaks = seq(0, 2, 0.1), limits = c(0, 2))

ggplot(results_df_top10, aes(x = TrainingAUC, y = ModelName)) +
  geom_segment(aes(x = TrainingAUC_lower, xend = TrainingAUC_upper, y = ModelName, yend = ModelName),
               color = "black", size = 0.5) +
  geom_errorbarh(aes(xmin = TrainingAUC_lower, xmax = TrainingAUC_upper, y = ModelName),
                 height = 0.2, color = "black", size = 0.5, show.legend = FALSE) +
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 0),
               color = "black", linetype = "solid", size = 0.5) +
  geom_vline(xintercept = 0.5, linetype = "solid", size = 0.3) +
  geom_point(aes(shape = factor(sign(TrainingAUC)), fill = factor(sign(TrainingAUC))),
             size = 5, color = "black") +
  geom_text(aes(label = paste(sprintf("%.3f", TrainingAUC), "[", sprintf("%.3f", TrainingAUC_lower), ",", sprintf("%.3f", TrainingAUC_upper), "]")),
            x = 1.2, hjust = 0, size = 3, vjust = 0.5, nudge_x = 0.1, family = "Times New Roman", fontface = "bold", color = "black") +
  labs(x = "Training AUC", y = "Model Name") +
  scale_shape_manual(values = c(22, 21), labels = c("Negative", "Positive")) +
  scale_fill_manual(values = c("blue", "red"), labels = c("Negative", "Positive")) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.margin = margin(0, 2, 0, 0, "cm"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line.y = element_blank(),
        text = element_text(family = "Times New Roman", face = "bold", color = "black")) +
  coord_cartesian(xlim = c(0, 2)) +
  scale_x_continuous(breaks = seq(0, 2, 0.1), limits = c(0, 2))

```

```{r }
library(xgboost)
library(shapviz)

xgbdata<-discover_queue[, c("Outcome", candidate_variables)]
xgbdata$Outcome <- as.numeric(as.character(xgbdata$Outcome))
dtrain <- xgb.DMatrix(data.matrix(xgbdata[candidate_variables]), label = xgbdata$Outcome)
fit_models$xgbTree_Fit$finalModel
param <- list(
  eta = "0.3",
  max_depth = "1",
  gamma = "0",
  colsample_bytree = "0.6",
  min_child_weight = "1",
  subsample = "1"
  #objective = "binary:logistic"
)
fit <- xgb.train(params = list(eta = param$eta
                               #max_depth = param$max_depth
                                 #gamma = param$gamma,
                               #colsample_bytree = param$colsample_bytree
                                 #min_child_weight = param$min_child_weight, 
                               #subsample = param$subsample
                               ), data = dtrain, nrounds = 50)
xgbdata_test<-validation_queue[, c("Outcome", candidate_variables)]
dtrain_test <- xgb.DMatrix(data.matrix(xgbdata_test[candidate_variables]), label = xgbdata_test$Outcome)
pred_val <- predict(fit, newdata = dtrain_test, type = "prob")
roc_training <- roc(xgbdata_test$Outcome,pred_val)
auc_training <- auc(roc_training)
auc_training
auc_ci_training <- ci(auc_training)
auc_ci_training
# Explanation data
xgb_test<-validation_queue[, c("Outcome", candidate_variables)]
shp <- shapviz(fit, X_pred = data.matrix(xgb_test[candidate_variables]), X = xgb_test)
sv_waterfall(shp, row_id = 4)
sv_force(shp, row_id = 4)
sv_importance(shp)
sv_importance(shp, kind = "beeswarm")
```

```{r}
library(predtools)
library(dplyr)
dev_data <- discover_queue[, c("Outcome", candidate_variables)]
#dev_data <- validation_queue[, c("Outcome", candidate_variables)]
dev_data$Outcome <- as.numeric(dev_data$Outcome)
dev_data$Outcome <- ifelse(dev_data$Outcome == 1, 0, 1)
n <-5 
top_models <- results_df %>% top_n(n, 验证集AUC)
model_names <- top_models$fit_name
predictions <- vector("list", length = n)
for (i in 1:n) {
  model <- model_names[i]
  predictions[[i]] <- predict(fit_models[[model]], newdata = dev_data, type = "prob")[, "Yes"]
}
dev_data_combined <- data.frame(
  Outcome = dev_data$Outcome,
  model = rep(model_names, each = nrow(dev_data)),
  predictions = unlist(predictions)
)
calibration_plot_my(
  obs = "Outcome",
  pred = "predictions",
  data = dev_data_combined,
  group = "model",
  nTiles = 4
)
calibration_curve_plot_my(
  obs = "Outcome",
  pred = "predictions",
  data = dev_data_combined,
  group = "model",
  nTiles = 3
)
```

```{r }
library(predtools)
#dev_data <- discover_queue[, c("Outcome", candidate_variables)]
dev_data <- validation_queue[, c("Outcome", candidate_variables)]
dev_data$Outcome <- as.numeric(dev_data$Outcome)
dev_data$Outcome <- ifelse(dev_data$Outcome == 1, 0, 1)
n <-5  
top_models <- results_df %>% top_n(n, 验证集AUC)
model_names <- top_models$fit_name
predictions <- vector("list", length = n)
for (i in 1:n) {
  model <- model_names[i]
  predictions[[i]] <- predict(fit_models[[model]], newdata = dev_data, type = "prob")[, "Yes"]
}
dev_data_combined <- data.frame(
  Outcome = dev_data$Outcome,
  model = rep(model_names, each = nrow(dev_data)),
  predictions = unlist(predictions)
)
calibration_plot_my(
  obs = "Outcome",
  pred = "predictions",
  data = dev_data_combined,
  group = "model",
  nTiles = 4
)

calibration_curve_plot_my(
  obs = "Outcome",
  pred = "predictions",
  data = dev_data_combined,
  group = "model",
  nTiles = 3
)
```


```{r }
library(plyr)
library(dplyr)
dev_data <- validation_queue[, c("Outcome", candidate_variables)]
n <- 15 
#n <- sum(results_df$p_value_val >= 0.05 | is.na(results_df$p_value_val)) # 指定所有五差异的模型
top_models <- results_df %>% top_n(n, 验证集AUC)
model_names <- top_models$fit_name
brier_scores <- c()
for (i in 1:n) {
  model <- model_names[i]
  predicted_probs <- predict(fit_models[[model]], newdata = dev_data, type = "prob")[, "Yes"]
  actual_outcomes <- ifelse(as.numeric(dev_data$Outcome) == 1, 0, 1)
  brier_score <- mean((actual_outcomes - predicted_probs)^2)
  brier_scores <- c(brier_scores, brier_score)
}
reference_index <- which.min(brier_scores)
reference_model <- model_names[reference_index]
reference_preds <- predict(fit_models[[reference_model]], newdata = dev_data, type = "prob")[, "Yes"]
reference_actuals <- ifelse(as.numeric(dev_data$Outcome) == 1, 0, 1)
reference_brier <- mean((reference_actuals - reference_preds)^2)

brier_table <- data.frame(Model = character(),
                          Brier_Score = numeric(),
                          Lower_CI = numeric(),
                          Upper_CI = numeric(),
                          P_Value = numeric(),
                          stringsAsFactors = FALSE)

for (i in 1:n) {
  model <- model_names[i]
  predicted_probs <- predict(fit_models[[model]], newdata = dev_data, type = "prob")[, "Yes"]
  actual_outcomes <- ifelse(as.numeric(dev_data$Outcome) == 1, 0, 1)
  
  brier_score <- mean((actual_outcomes - predicted_probs)^2)

  bootstrap_scores <- replicate(1000, {
    sampled_indices <- sample(1:length(predicted_probs), replace = TRUE)
    sampled_actuals <- actual_outcomes[sampled_indices]
    sampled_preds <- predicted_probs[sampled_indices]
    mean((sampled_actuals - sampled_preds)^2)
  })
  lower_ci <- quantile(bootstrap_scores, 0.025)
  upper_ci <- quantile(bootstrap_scores, 0.975)
  
  if (i != reference_index) {
    reference_bootstrap_scores <- replicate(1000, {
      sampled_indices <- sample(1:length(reference_preds), replace = TRUE)
      sampled_actuals <- reference_actuals[sampled_indices]
      sampled_preds <- reference_preds[sampled_indices]
      mean((sampled_actuals - sampled_preds)^2)
    })
    p_value <- sum(reference_bootstrap_scores <= brier_score) / length(reference_bootstrap_scores)
  } else {
    p_value <- NA
  }
  
  brier_table <- rbind(brier_table, data.frame(Model = model,
                                               Brier_Score = brier_score,
                                               Lower_CI = lower_ci,
                                               Upper_CI = upper_ci,
                                               P_Value = p_value,
                                               stringsAsFactors = FALSE))
}

brier_table <- arrange(brier_table, Brier_Score)

save(brier_table, file = "~/建模/Data/brier_table.rdata")

```


```{r }

brier_result_df <- data.frame(Variable = brier_table$Model,
                        Beta_Values = brier_table$Brier_Score,
                        Lower_CI = brier_table$Lower_CI,
                        Upper_CI = brier_table$Upper_CI,
                        stringsAsFactors = FALSE)

brier_result_df <- brier_result_df[order(-brier_result_df$Beta_Values), ]
#brier_result_df <- brier_result_df[order(brier_result_df$Beta_Values), ]

brier_result_df$Variable <- factor(brier_result_df$Variable, levels = brier_result_df$Variable)

library(ggplot2)

lower<-0
upper<-0.2
gap<-0.1
word<-0.3

ggplot(brier_result_df, aes(x = Beta_Values, y = Variable)) +
  geom_segment(aes(x = Lower_CI, xend = Upper_CI, y = Variable, yend = Variable),
               color = "black", size = 0.5) +
  geom_errorbarh(aes(xmin = Lower_CI, xmax = Upper_CI, y = Variable),
                 height = 0.2, color = "black", size = 0.5, show.legend = FALSE) +
  geom_segment(aes(x = 0, xend = upper, y = 0, yend = 0),
               color = "black", linetype = "solid", size = 0.5) +
  geom_vline(xintercept = 0, linetype = "solid", size = 0.3) +
  geom_point(aes(shape = factor(sign(Beta_Values)), fill = factor(sign(Beta_Values))),
             size = 5, color = "black") +
  geom_text(aes(label = paste(sprintf("%.3f", Beta_Values), "[", sprintf("%.3f", Lower_CI), ",", sprintf("%.3f", Upper_CI), "]")),
            x = word, hjust = 0, size = 3, vjust = 0.5, nudge_x = 0.1, family = "Times New Roman", fontface = "bold", color = "black") +
  labs(x = "Beta Value", y = "Variable") +
  scale_shape_manual(values = c(22, 21), labels = c("Negative", "Positive")) +
  scale_fill_manual(values = c("red", "red"), labels = c("Negative", "Positive")) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.margin = margin(0, 1, 0, 0, "cm"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line.y = element_blank(),
        text = element_text(family = "Times New Roman", face = "bold", color = "black")) +
  coord_cartesian(xlim = c(0, 1)) +
  scale_x_continuous(breaks = seq(lower, upper, gap), limits = c(lower, upper))

```



```{r }
library(pROC)
#data_ROC<-discover_queue 
data_ROC<-validation_queue
n <- 5 
sorted_results <- results_df[order(results_df$验证集AUC, decreasing = TRUE), ]
top_models <- sorted_results$fit_name[1:n]

roc_data_list <- vector("list", n)
auc_list <- vector("list", n)
ci_list <- vector("list", n)
for (i in 1:n) {
  model <- fit_models[[top_models[i]]]
  pred <- predict(model, newdata = data_ROC[, c("Outcome", candidate_variables)], type = "prob")
  roc_data <- roc(data_ROC$Outcome, pred$Yes)
  roc_data_list[[i]] <- roc_data
  auc_list[[i]] <- auc(roc_data)
  ci_list[[i]] <- ci.auc(roc_data)
}

roc_df <- data.frame()
smoothed_roc_df <- data.frame()
for (i in 1:n) {
  roc_data <- roc_data_list[[i]]
  auc <- auc_list[[i]]
  ci <- ci_list[[i]]
  smoothed_roc <- smooth(roc_data, method = "density")
  roc_df <- rbind(roc_df, data.frame(Specificity = 1 - roc_data$specificities,
                                     Sensitivity = roc_data$sensitivities,
                                     Model = top_models[i],
                                     AUC = round(auc, 3),
                                     CI = paste0("[", round(ci[1], 3), ", ", round(ci[3], 3), "]")))
  smoothed_roc_df <- rbind(smoothed_roc_df, data.frame(Specificity = 1 - smoothed_roc$specificities,
                                                       Sensitivity = smoothed_roc$sensitivities,
                                                       Model = top_models[i]))
}

ggplot() +
  #geom_line(data = roc_df, aes(x = Specificity, y = Sensitivity, color = Model)) +
  geom_line(data = smoothed_roc_df, aes(x = Specificity, y = Sensitivity, color = Model), linetype = "solid") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  xlim(0, 1) +
  ylim(0, 1) +
  xlab("False Positive Rate") +
  ylab("True Positive Rate") +
  ggtitle("ROC Curve") +
  theme(panel.border = element_rect(color = "black", fill = NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white")) +
  scale_color_manual(values = rainbow(n), labels = top_models, guide = guide_legend())

```



```{r}

library(tableone)

load("~/Data/data.rdata")
str(data)
myVars <- names(data)[names(data) != "Group"]
catVars <- c()
for (var in myVars) {
  if (is.factor(data[[var]])) {
    catVars <- c(catVars, var)
  }
}

nonvar <- c()
for (var in names(data)) {
  if (is.numeric(data[[var]])) {
    shapiro_result <- shapiro.test(data[[var]])
    if (shapiro_result$p.value > 0.05) {
      # 符合正态分布，不做任何操作
    } else {
      nonvar <- c(nonvar, var)
    }
  }
}

exactvars <- c()
for (var in names(data)) {
  if (is.factor(data[[var]])) {
    table <- table(data[[var]])
    n <- sum(table)
    
    if (n >= 40 && sum(table < 5) >= 2 && any(table < 5)) {
      exactvars <- c(exactvars, var)
    }
    
    if (n < 40 || any(table < 1)) {
      exactvars <- c(exactvars, var)
    }
    
  }
}

table <- CreateTableOne(vars = myVars, 
                        factorVars = catVars,
                        strata = "Group",
                        data = data,
                        addOverall = TRUE) 


write.csv(table1, file = "~/Data/table1.csv")

myVars_table2 <- names(data)[!(names(data) %in% c("Group", "Outcome"))]

table2 <- CreateTableOne(vars = myVars_table2, 
                        factorVars = catVars,
                        strata = "Outcome", 
                        data = data, 
                        addOverall = TRUE) 



write.csv(table2, file = "~/Data/table2.csv")


table(data$Group)

discover_data <- data[data$Group == "Discover", ]

myVars_table3 <- names(discover_data)[!(names(discover_data) %in% c("Group", "Outcome"))]

table3 <- CreateTableOne(vars = myVars_table3, 
                         factorVars = catVars,
                         strata = "Outcome", 
                         data = discover_data, 
                         addOverall = TRUE) 


write.csv(table3, file = "~/Data/table3.csv")

table(data$Group)
Validation_data <- data[data$Group == "Validation", ]
myVars_table4 <- names(Validation_data)[!(names(Validation_data) %in% c("Group", "Outcome"))]

table4 <- CreateTableOne(vars = myVars_table4, 
                         factorVars = catVars,
                         strata = "Outcome", 
                         data = Validation_data, 
                         addOverall = TRUE)
write.csv(table4, file = "~/Data/table4.csv")

```



```{r }
source("~/Code/dca.r")
library(reshape2)
library(ggplot2)

test_data <- discover_queue[, c("Outcome", candidate_variables)]
#test_data <- validation_queue[, c("Outcome", candidate_variables)]

test_data$Outcome <- as.numeric(test_data$Outcome)
test_data$Outcome <- ifelse(test_data$Outcome == 1, 0, 1)
n <- 5  

top_models <- results_df %>% top_n(n, AUC)
model_names <- top_models$fit_name

dca_results <- data.frame() 

for (i in 1:n) {
  model <- model_names[[i]]
  prob <- predict(fit_models[[model]], newdata = test_data, type = "prob")
  prob <- data.frame("outcome" = test_data$Outcome, "model_prob" = as.data.frame(prob)$Yes)
  
  dcaoutput <- dca(data = prob, outcome = "outcome",
                   predictors = c("model_prob"),
                   xstart = 0, xstop = 1, ymin = 0)
  dcadf <- data.frame(dcaoutput$net.benefit)
  
  temp <- melt(dcadf, id = "threshold", measure = c("model_prob", "all", "none"))
  
  temp$model <- model_names[[i]]
  
  dca_results <- rbind(dca_results, temp)
}

save(dca_results,file="~/Data/dca_results.rdata")
write.csv(dca_results, file = "~/Data/dca_results.csv")
library(RColorBrewer)

color_palette <- brewer.pal(n = length(unique(dca_results$model)), name = "Set1")
#color_palette <- brewer.pal(n = length(unique(dca_results$model)), name = "Paired")

# Sort unique model names alphabetically
model_names <- sort(unique(dca_results$model))

# Define colors for none and all
none_color <- "red"
all_color <- "black"

# Assign colors from color_palette to the remaining model names
model_colors <- color_palette[order(model_names)]

# Create a named color vector
color_vector <- c(none = none_color, all = all_color, setNames(model_colors, model_names))

ggplot(dca_results, aes(x = threshold, y = value, linetype = model)) +
  geom_line(data = subset(subset(dca_results, model == model_names[[1]]), variable != "model_prob"), aes(color = variable), linetype = "dashed", size = 0.5) +
  geom_smooth(data = subset(dca_results, variable == "model_prob"), aes(color = model), method = "loess", se = FALSE, size = 0.7) +
  coord_cartesian(xlim = c(0, 1), ylim = c(-0.05, max(dca_results$value, na.rm = TRUE))) +
  labs(x = "Threshold probability (%)", y = "Net benefit") +
  scale_color_manual(values = color_vector) +
  scale_linetype_manual(values = rep("solid", length(unique(dca_results$model)))) +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_blank())

```


```{r}
library(dplyr)

all_models <- getModelInfo()

model_table <- data.frame(
  ModelName = character(),
  Label = character(),
  Library = character(),
  Type = character(),
  Parameters = character(),
  stringsAsFactors = FALSE
)

for (model_name in names(all_models)) {
  model_info <- all_models[[model_name]]
  
  label <- model_info$label
  library <- paste(model_info$library, collapse = ", ")
  type <- paste(model_info$type, collapse = ", ")
  parameters <- paste(model_info$parameters$parameter, collapse = ", ")
  model_table <- model_table %>%
    add_row(
      ModelName = model_name,
      Label = label,
      Library = library,
      Type = type,
      Parameters = parameters
    )
}

model_table
save(model_table,file="~/Data/model_table.rdata")
str(results_df)
merged_df <- merge(results_df, model_table, by.x = "模型名字", by.y = "ModelName", all.x = TRUE)
merged_df
write.csv(merged_df, file = "~/Data/merged_df.csv")

parameter_table <- data.frame(
  ModelName = character(),
  bestTune = character(),
  stringsAsFactors = FALSE
)

for (model_name in names(fit_models)) {
  best_params <- fit_models[[model_name]]$bestTune
  best_params_formatted <- paste(names(best_params), "=", best_params, collapse = "； ")
  parameter_table <- parameter_table %>%
    add_row(
      ModelName = model_name,
      bestTune = best_params_formatted
    )
}
parameter_table
write.csv(parameter_table, file = "~/Data/parameter_table.csv")
all_models_infor <- merge(merged_df, parameter_table, by.x = "fit_name", by.y = "ModelName", all.x = TRUE)
all_models_infor

write.csv(all_models_infor, file = "~/Data/all_models_infor.csv")
```











